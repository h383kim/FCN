{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640c543e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:45.529986Z",
     "iopub.status.busy": "2024-11-26T18:11:45.529646Z",
     "iopub.status.idle": "2024-11-26T18:11:49.178354Z",
     "shell.execute_reply": "2024-11-26T18:11:49.177663Z"
    },
    "papermill": {
     "duration": 3.656709,
     "end_time": "2024-11-26T18:11:49.180330",
     "exception": false,
     "start_time": "2024-11-26T18:11:45.523621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ae34d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:49.190230Z",
     "iopub.status.busy": "2024-11-26T18:11:49.189570Z",
     "iopub.status.idle": "2024-11-26T18:11:49.249702Z",
     "shell.execute_reply": "2024-11-26T18:11:49.248610Z"
    },
    "papermill": {
     "duration": 0.06741,
     "end_time": "2024-11-26T18:11:49.252131",
     "exception": false,
     "start_time": "2024-11-26T18:11:49.184721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252cb3a6",
   "metadata": {
    "papermill": {
     "duration": 0.003907,
     "end_time": "2024-11-26T18:11:49.260287",
     "exception": false,
     "start_time": "2024-11-26T18:11:49.256380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb49f6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:49.270434Z",
     "iopub.status.busy": "2024-11-26T18:11:49.269911Z",
     "iopub.status.idle": "2024-11-26T18:11:50.763575Z",
     "shell.execute_reply": "2024-11-26T18:11:50.762870Z"
    },
    "papermill": {
     "duration": 1.500323,
     "end_time": "2024-11-26T18:11:50.765634",
     "exception": false,
     "start_time": "2024-11-26T18:11:49.265311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as transforms_F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e0e896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:50.775469Z",
     "iopub.status.busy": "2024-11-26T18:11:50.775057Z",
     "iopub.status.idle": "2024-11-26T18:11:50.796969Z",
     "shell.execute_reply": "2024-11-26T18:11:50.796370Z"
    },
    "papermill": {
     "duration": 0.02854,
     "end_time": "2024-11-26T18:11:50.798594",
     "exception": false,
     "start_time": "2024-11-26T18:11:50.770054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_df = pd.read_csv('/kaggle/input/camvid/CamVid/class_dict.csv')\n",
    "# Create a dictionary that maps rgb value to 32 CamVid's class indices\n",
    "RGB2label_dict = {\n",
    "    (row['r'], row['g'], row['b']): idx\n",
    "    for idx, row in class_df.iterrows()\n",
    "}\n",
    "label2RGB_dict = {\n",
    "    v: k for k, v in RGB2label_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f95f715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:50.807939Z",
     "iopub.status.busy": "2024-11-26T18:11:50.807665Z",
     "iopub.status.idle": "2024-11-26T18:11:50.817834Z",
     "shell.execute_reply": "2024-11-26T18:11:50.816991Z"
    },
    "papermill": {
     "duration": 0.016684,
     "end_time": "2024-11-26T18:11:50.819405",
     "exception": false,
     "start_time": "2024-11-26T18:11:50.802721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CamVidDataset(Dataset):\n",
    "    def __init__(self, img_dir: str, label_dir: str, augmentation: bool=False):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.augmentation = augmentation\n",
    "        self.img_files = os.listdir(self.img_dir)\n",
    "        self.label_files = os.listdir(self.label_dir)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((384, 480)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def _augment(self, image: torch.Tensor, label: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Horizontal flip with p=0.5\n",
    "        if torch.randn(1) > 0.5:\n",
    "            image = transforms_F.hflip(image)\n",
    "            label = transforms_F.hflip(label)\n",
    "        # Pad for cropping\n",
    "        image = transforms_F.pad(image, (10, 10, 10, 10))\n",
    "        label = transforms_F.pad(label, (10, 10, 10, 10))\n",
    "        # RandomCrop\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(384, 480))\n",
    "        image = transforms_F.crop(image, i, j, h, w)\n",
    "        label = transforms_F.crop(label, i, j, h, w)\n",
    "\n",
    "        image = transforms.ColorJitter(brightness=0.1, contrast=0, saturation=0, hue=0.2)(image)\n",
    "        return image, label\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_file = self.img_files[idx]\n",
    "        label_file = self.label_files[idx]\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, img_file)\n",
    "        label_path = os.path.join(self.label_dir, label_file)\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "        label = Image.open(label_path)\n",
    "\n",
    "        # Transform\n",
    "        image = self.transform(image).to(DEVICE)\n",
    "        label = self.transform(label).to(DEVICE)\n",
    "\n",
    "        # If augmentation is on, apply augmentation\n",
    "        if self.augmentation:\n",
    "            image, label = self._augment(image, label)\n",
    "\n",
    "        # Masking label image pixel by pixel\n",
    "        label = label.permute(1, 2, 0) # (C, H, W) -> (H, W, C)\n",
    "        label = (label * 255).int() # Scale back to 0~255 as torch.ToTensor() scaled the image to 0~1\n",
    "        masked_label = torch.zeros(label.size(0), label.size(1), dtype=torch.uint8, device=DEVICE)\n",
    "        for rgb, idx in RGB2label_dict.items(): # Mask the pixels for every class type\n",
    "            rgb_tensor = torch.tensor(rgb, device=DEVICE)\n",
    "            masked_label[(label == rgb_tensor).all(axis=-1)] = idx\n",
    "\n",
    "        return image, masked_label.long()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d1ec63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:50.828543Z",
     "iopub.status.busy": "2024-11-26T18:11:50.828008Z",
     "iopub.status.idle": "2024-11-26T18:11:50.852065Z",
     "shell.execute_reply": "2024-11-26T18:11:50.851242Z"
    },
    "papermill": {
     "duration": 0.030311,
     "end_time": "2024-11-26T18:11:50.853737",
     "exception": false,
     "start_time": "2024-11-26T18:11:50.823426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_img_dir = '/kaggle/input/camvid/CamVid/train'\n",
    "train_label_dir ='/kaggle/input/camvid/CamVid/train_labels'\n",
    "train_dataset = CamVidDataset(train_img_dir, train_label_dir, False)\n",
    "\n",
    "val_img_dir = '/kaggle/input/camvid/CamVid/val'\n",
    "val_label_dir = '/kaggle/input/camvid/CamVid/val_labels'\n",
    "val_dataset = CamVidDataset(val_img_dir, val_label_dir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2b475d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:50.863076Z",
     "iopub.status.busy": "2024-11-26T18:11:50.862627Z",
     "iopub.status.idle": "2024-11-26T18:11:51.370410Z",
     "shell.execute_reply": "2024-11-26T18:11:51.369230Z"
    },
    "papermill": {
     "duration": 0.515112,
     "end_time": "2024-11-26T18:11:51.373005",
     "exception": false,
     "start_time": "2024-11-26T18:11:50.857893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 384, 480])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b672b81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:51.388172Z",
     "iopub.status.busy": "2024-11-26T18:11:51.387882Z",
     "iopub.status.idle": "2024-11-26T18:11:51.393055Z",
     "shell.execute_reply": "2024-11-26T18:11:51.392301Z"
    },
    "papermill": {
     "duration": 0.014327,
     "end_time": "2024-11-26T18:11:51.394632",
     "exception": false,
     "start_time": "2024-11-26T18:11:51.380305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb0fb2",
   "metadata": {
    "papermill": {
     "duration": 0.005558,
     "end_time": "2024-11-26T18:11:51.408503",
     "exception": false,
     "start_time": "2024-11-26T18:11:51.402945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1f273e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:51.419490Z",
     "iopub.status.busy": "2024-11-26T18:11:51.419216Z",
     "iopub.status.idle": "2024-11-26T18:11:51.429815Z",
     "shell.execute_reply": "2024-11-26T18:11:51.429054Z"
    },
    "papermill": {
     "duration": 0.01726,
     "end_time": "2024-11-26T18:11:51.431260",
     "exception": false,
     "start_time": "2024-11-26T18:11:51.414000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class FCN_8s(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        vgg16 = models.vgg16_bn(weights=\"IMAGENET1K_V1\", progress=True)\n",
    "\n",
    "        # Use the features from vgg16\n",
    "        self.features = vgg16.features\n",
    "\n",
    "        # Replace the classifier with convolutional layers\n",
    "        self.score_pool4 = nn.Sequential(\n",
    "            nn.Conv2d(512, num_classes, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.score_pool3 = nn.Sequential(\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "        self.score_fr = nn.Sequential(\n",
    "            nn.Conv2d(512, 4096, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(4096, 4096, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(4096, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        # Transposed convolution layers for upsampling\n",
    "        '''\n",
    "        score_fr*2 means score_fr upsampled by factor of 2 using Transposed Convolution\n",
    "        '''\n",
    "        # self.upscore_pool5 = nn.ConvTranspose2d(\n",
    "        #     num_classes, num_classes, kernel_size=4, stride=2, padding=1\n",
    "        # ) # Upsamples the score_fr by factor of 2\n",
    "        # self.upscore_pool4 = nn.ConvTranspose2d(\n",
    "        #     num_classes, num_classes, kernel_size=4, stride=2, padding=1\n",
    "        # ) # Upsamples the (score_fr*2 + score_pool4) by factor of 2\n",
    "        # self.upscore_pool3 = nn.ConvTranspose2d(\n",
    "        #     num_classes, num_classes, kernel_size=16, stride=8, padding=4\n",
    "        # ) # Upsamples the [(score_fr*2 + score_pool4)*2 + score_pool3] by factor of 8\n",
    "        self.upscore_pool5 = nn.ConvTranspose2d(\n",
    "            num_classes, num_classes, kernel_size=2, stride=2, bias=False\n",
    "        ) # Upsamples the score_fr by factor of 2\n",
    "        self.upscore_pool4 = nn.ConvTranspose2d(\n",
    "            num_classes, num_classes, kernel_size=2, stride=2, bias=False\n",
    "        ) # Upsamples the (score_fr*2 + score_pool4) by factor of 2\n",
    "        self.upscore_pool3 = nn.ConvTranspose2d(\n",
    "            num_classes, num_classes, kernel_size=8, stride=8, bias=False\n",
    "        ) # Upsamples the [(score_fr*2 + score_pool4)*2 + score_pool3] by factor of 8\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Store intermediate outputs for skip connections\n",
    "        pool3 = None\n",
    "        pool4 = None\n",
    "\n",
    "        '''input x: [N, 3, 384, 480] '''\n",
    "        # Forward pass through VGG16 features\n",
    "        for i in range(len(self.features)):\n",
    "            x = self.features[i](x) # Feed forwarding the previous output to each layer coming next\n",
    "            if i == 23: # After pool_3 layer passed\n",
    "                pool3 = x \n",
    "                ''' pool3: [N, 256, 48, 60] '''\n",
    "            elif i == 33: # After pool_4 layer passed\n",
    "                pool4 = x \n",
    "                ''' pool4: [N, 512, 24, 30] '''\n",
    "            elif i == 43: \n",
    "                ''' x: [N, 512, 12, 15] '''\n",
    "                break;\n",
    "\n",
    "        # Classify the features\n",
    "        # x is now the output from the last pooling layer(pool_5) of vgg16_bn\n",
    "        ''' x: [N, 32, 12, 15] '''\n",
    "        x = self.score_fr(x) # (N, num_classes, H/32, W/32)\n",
    "\n",
    "        # Upsample the pool5 score by factor of 2\n",
    "        ''' x: [N, 32, 24, 30] '''\n",
    "        x = self.upscore_pool5(x) # (N, num_classes, H/16, W/16)\n",
    "        # Add skip connection from pool4\n",
    "        ''' score_pool4: [N, 32, 24, 30] '''\n",
    "        score_pool4 = self.score_pool4(pool4)\n",
    "        x = x + score_pool4\n",
    "\n",
    "        # Upsample the skip-connected pool4+pool5 score by factor of 2\n",
    "        ''' x: [N, 32, 48, 60] '''\n",
    "        x = self.upscore_pool4(x) # (N, num_classes, H/8, W/8)\n",
    "        # Add skip connection from pool3\n",
    "        ''' score_pool3: [N, 32, 48, 60] '''\n",
    "        score_pool3 = self.score_pool3(pool3)\n",
    "        x = x + score_pool3\n",
    "\n",
    "        # Finally, upsample the skip-connected pool3+pool4+pool5 score by factor of 8\n",
    "        x = self.upscore_pool3(x) # (N, num_classes, H, W)\n",
    "        ''' x: [N, 32, 384, 480] '''\n",
    "        # The output tensor now has the same spatial dimensions as the input\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5382c077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:51.440329Z",
     "iopub.status.busy": "2024-11-26T18:11:51.440055Z",
     "iopub.status.idle": "2024-11-26T18:11:55.727453Z",
     "shell.execute_reply": "2024-11-26T18:11:55.726490Z"
    },
    "papermill": {
     "duration": 4.294218,
     "end_time": "2024-11-26T18:11:55.729585",
     "exception": false,
     "start_time": "2024-11-26T18:11:51.435367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
      "100%|██████████| 528M/528M [00:02<00:00, 241MB/s]\n"
     ]
    }
   ],
   "source": [
    "fcn_8s = FCN_8s(num_classes=32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0ac80",
   "metadata": {
    "papermill": {
     "duration": 0.00504,
     "end_time": "2024-11-26T18:11:55.740302",
     "exception": false,
     "start_time": "2024-11-26T18:11:55.735262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8ac770b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:55.752728Z",
     "iopub.status.busy": "2024-11-26T18:11:55.751931Z",
     "iopub.status.idle": "2024-11-26T18:11:55.756093Z",
     "shell.execute_reply": "2024-11-26T18:11:55.755388Z"
    },
    "papermill": {
     "duration": 0.012245,
     "end_time": "2024-11-26T18:11:55.757771",
     "exception": false,
     "start_time": "2024-11-26T18:11:55.745526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_acc_dict = {\n",
    "    'train_loss_lst' : [],\n",
    "    'train_acc_lst' : [],\n",
    "    'val_loss_lst' : [],\n",
    "    'val_acc_lst' : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb806634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:55.769873Z",
     "iopub.status.busy": "2024-11-26T18:11:55.769560Z",
     "iopub.status.idle": "2024-11-26T18:11:55.778788Z",
     "shell.execute_reply": "2024-11-26T18:11:55.778114Z"
    },
    "papermill": {
     "duration": 0.017027,
     "end_time": "2024-11-26T18:11:55.780274",
     "exception": false,
     "start_time": "2024-11-26T18:11:55.763247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def label_to_rgb_tensor(label_tensor: torch.Tensor) -> torch.Tensor:\n",
    "    height, width = label_tensor.shape\n",
    "    rgb_image = torch.zeros(3, height, width, dtype=torch.uint8)\n",
    "\n",
    "    for label, rgb in label2RGB_dict.items():\n",
    "        mask = (label_tensor == label)\n",
    "        rgb_image[0][mask] = rgb[0]  # Red\n",
    "        rgb_image[1][mask] = rgb[1]  # Green\n",
    "        rgb_image[2][mask] = rgb[2]  # Blue\n",
    "\n",
    "    return rgb_image\n",
    "\n",
    "def visualize_segmentation(model, val_loader, device, epoch):\n",
    "    model.eval()\n",
    "    batch_idx = random.randint(0, len(val_loader) - 1)\n",
    "    images, labels = list(val_loader)[batch_idx]\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    img_idx = random.randint(0, len(images) - 1)\n",
    "    img = images[img_idx].cpu().numpy().transpose(1, 2, 0)\n",
    "    label = labels[img_idx].cpu().numpy()\n",
    "    pred = preds[img_idx].cpu().numpy()\n",
    "    pred_rgb = label_to_rgb_tensor(pred).cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Original Image')\n",
    "    \n",
    "    axes[1].imshow(label_to_rgb_tensor(label).permute(1, 2, 0).cpu().numpy())\n",
    "    axes[1].set_title('Ground Truth')\n",
    "\n",
    "    axes[2].imshow(pred_rgb)\n",
    "    axes[2].set_title('Predicted Mask')\n",
    "\n",
    "    # 이미지 파일 저장\n",
    "    output_path = f'/kaggle/working/segmentation_epoch_{epoch}.png'\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Segmentation visualization saved at {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2660cf66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:55.793155Z",
     "iopub.status.busy": "2024-11-26T18:11:55.792904Z",
     "iopub.status.idle": "2024-11-26T18:11:55.798688Z",
     "shell.execute_reply": "2024-11-26T18:11:55.797834Z"
    },
    "papermill": {
     "duration": 0.014444,
     "end_time": "2024-11-26T18:11:55.800363",
     "exception": false,
     "start_time": "2024-11-26T18:11:55.785919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataloader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    total_pixels, correct_pixels = 0, 0\n",
    "\n",
    "    for images, label_images in tqdm(dataloader):\n",
    "        images = images.to(DEVICE)\n",
    "        label_images = label_images.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_logits = model(images)\n",
    "        loss = loss_fn(y_logits, label_images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        # y_preds: (N, H, W)\n",
    "        y_preds = torch.argmax(y_logits, axis=1) # argmax along channels (N, C, H, W)\n",
    "        correct_pixels += (label_images == y_preds).sum().item()\n",
    "        total_pixels += label_images.numel()\n",
    "\n",
    "    # Calculate average loss and accuracy for the batch\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc = 100 * (correct_pixels / total_pixels)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "013b1308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:55.815302Z",
     "iopub.status.busy": "2024-11-26T18:11:55.815024Z",
     "iopub.status.idle": "2024-11-26T18:11:55.819970Z",
     "shell.execute_reply": "2024-11-26T18:11:55.819262Z"
    },
    "papermill": {
     "duration": 0.015084,
     "end_time": "2024-11-26T18:11:55.821555",
     "exception": false,
     "start_time": "2024-11-26T18:11:55.806471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, optimizer, loss_fn):\n",
    "    model.eval()\n",
    "    val_loss, val_acc = 0.0, 0.0\n",
    "    correct_pixels, total_pixels = 0, 0\n",
    "\n",
    "    for images, label_images, in dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        label_images = label_images.to(DEVICE)\n",
    "\n",
    "        y_logits = model(images)\n",
    "        loss = loss_fn(y_logits, label_images)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        y_preds = torch.argmax(y_logits, axis=1)\n",
    "        correct_pixels += (label_images == y_preds).sum().item()\n",
    "        total_pixels += label_images.numel()\n",
    "\n",
    "    # Average loss/acc over the batches\n",
    "    val_loss /= len(dataloader)\n",
    "    val_acc = 100 * (correct_pixels / total_pixels)\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4bb1d5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:55.832951Z",
     "iopub.status.busy": "2024-11-26T18:11:55.832705Z",
     "iopub.status.idle": "2024-11-26T18:11:55.839504Z",
     "shell.execute_reply": "2024-11-26T18:11:55.838800Z"
    },
    "papermill": {
     "duration": 0.014151,
     "end_time": "2024-11-26T18:11:55.840923",
     "exception": false,
     "start_time": "2024-11-26T18:11:55.826772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "def train_model(model, \n",
    "                train_dataloader, \n",
    "                val_dataloader,\n",
    "                optimizer,\n",
    "                loss_fn,\n",
    "                num_epochs=1):\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        start = time.time()\n",
    "        # Feed forward / backprop on train_dataloader\n",
    "        train_loss, train_acc = train(model, train_dataloader, optimizer, loss_fn)\n",
    "        # Feed forward on val_dataloader\n",
    "        val_loss, val_acc = evaluate(model, val_dataloader, optimizer, loss_fn)\n",
    "\n",
    "        # Storing epoch histories\n",
    "        loss_acc_dict['train_loss_lst'].append(train_loss)\n",
    "        loss_acc_dict['train_acc_lst'].append(train_acc)\n",
    "        loss_acc_dict['val_loss_lst'].append(val_loss)\n",
    "        loss_acc_dict['val_acc_lst'].append(val_acc)\n",
    "\n",
    "        # Update model depending on its peformance on validation data\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # Scheduler Update\n",
    "        # scheduler.step()\n",
    "        \n",
    "        end = time.time()\n",
    "        time_elapsed = end - start\n",
    "        print(f\"------------ epoch {epoch} ------------\")\n",
    "        print(f\"Train loss: {train_loss:.4f} | Train acc: {train_acc:.2f}%\")\n",
    "        print(f\"Validation loss: {val_loss:.4f} | Validation acc: {val_acc:.2f}%\")\n",
    "        print(f\"Time taken: {time_elapsed / 60:.0f}min {time_elapsed % 60:.0f}s\")\n",
    "\n",
    "        if (epoch - 1) % 10 == 0:\n",
    "            visualize_segmentation(model, val_dataloader, DEVICE, epoch - 1)\n",
    "\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e697d10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:55.853327Z",
     "iopub.status.busy": "2024-11-26T18:11:55.853060Z",
     "iopub.status.idle": "2024-11-26T18:11:55.856604Z",
     "shell.execute_reply": "2024-11-26T18:11:55.855924Z"
    },
    "papermill": {
     "duration": 0.012855,
     "end_time": "2024-11-26T18:11:55.858782",
     "exception": false,
     "start_time": "2024-11-26T18:11:55.845927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD([\n",
    "#     {'params': fcn_8s.features.parameters(), 'lr': 1e-4},\n",
    "#     {'params': fcn_8s.score_pool3.parameters(), 'lr': 1e-3},\n",
    "#     {'params': fcn_8s.score_pool4.parameters(), 'lr': 1e-3},\n",
    "#     {'params': fcn_8s.score_fr.parameters(), 'lr': 1e-3},\n",
    "#     {'params': fcn_8s.upscore_pool3.parameters(), 'lr': 1e-3},\n",
    "#     {'params': fcn_8s.upscore_pool4.parameters(), 'lr': 1e-3},\n",
    "#     {'params': fcn_8s.upscore_pool5.parameters(), 'lr': 1e-3}\n",
    "# ], momentum=0.9, weight_decay=0.0005)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "580c4b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:55.870240Z",
     "iopub.status.busy": "2024-11-26T18:11:55.869625Z",
     "iopub.status.idle": "2024-11-26T18:11:55.873928Z",
     "shell.execute_reply": "2024-11-26T18:11:55.873110Z"
    },
    "papermill": {
     "duration": 0.011702,
     "end_time": "2024-11-26T18:11:55.875576",
     "exception": false,
     "start_time": "2024-11-26T18:11:55.863874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcn_8s.parameters(), lr=1e-3)\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fd5d59e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:11:55.887705Z",
     "iopub.status.busy": "2024-11-26T18:11:55.887480Z",
     "iopub.status.idle": "2024-11-26T18:30:47.916879Z",
     "shell.execute_reply": "2024-11-26T18:30:47.915907Z"
    },
    "papermill": {
     "duration": 1132.038031,
     "end_time": "2024-11-26T18:30:47.918618",
     "exception": false,
     "start_time": "2024-11-26T18:11:55.880587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:38<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 1 ------------\n",
      "Train loss: 2.3386 | Train acc: 24.31%\n",
      "Validation loss: 2.0704 | Validation acc: 33.71%\n",
      "Time taken: 1min 46s\n",
      "Segmentation visualization saved at /kaggle/working/segmentation_epoch_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 2 ------------\n",
      "Train loss: 1.6890 | Train acc: 45.73%\n",
      "Validation loss: 1.6353 | Validation acc: 51.15%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 3 ------------\n",
      "Train loss: 1.5612 | Train acc: 51.70%\n",
      "Validation loss: 1.5063 | Validation acc: 54.05%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 4 ------------\n",
      "Train loss: 1.5019 | Train acc: 53.26%\n",
      "Validation loss: 1.5056 | Validation acc: 53.36%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 5 ------------\n",
      "Train loss: 1.4780 | Train acc: 53.53%\n",
      "Validation loss: 1.4971 | Validation acc: 53.75%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 6 ------------\n",
      "Train loss: 1.4481 | Train acc: 54.28%\n",
      "Validation loss: 1.4495 | Validation acc: 54.91%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 7 ------------\n",
      "Train loss: 1.4209 | Train acc: 54.94%\n",
      "Validation loss: 1.5282 | Validation acc: 53.73%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 8 ------------\n",
      "Train loss: 1.4070 | Train acc: 55.17%\n",
      "Validation loss: 1.4164 | Validation acc: 55.53%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 9 ------------\n",
      "Train loss: 1.4114 | Train acc: 55.14%\n",
      "Validation loss: 1.3953 | Validation acc: 55.99%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 10 ------------\n",
      "Train loss: 1.3959 | Train acc: 55.77%\n",
      "Validation loss: 1.4962 | Validation acc: 52.23%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 11 ------------\n",
      "Train loss: 1.3972 | Train acc: 55.65%\n",
      "Validation loss: 1.4423 | Validation acc: 55.11%\n",
      "Time taken: 1min 37s\n",
      "Segmentation visualization saved at /kaggle/working/segmentation_epoch_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 12 ------------\n",
      "Train loss: 1.3625 | Train acc: 56.57%\n",
      "Validation loss: 1.4340 | Validation acc: 54.70%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 13 ------------\n",
      "Train loss: 1.3590 | Train acc: 56.77%\n",
      "Validation loss: 1.5217 | Validation acc: 51.68%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 14 ------------\n",
      "Train loss: 1.3518 | Train acc: 57.16%\n",
      "Validation loss: 1.4931 | Validation acc: 54.02%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 15 ------------\n",
      "Train loss: 1.3389 | Train acc: 57.49%\n",
      "Validation loss: 1.4391 | Validation acc: 55.07%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 16 ------------\n",
      "Train loss: 1.3352 | Train acc: 57.56%\n",
      "Validation loss: 1.5830 | Validation acc: 54.07%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 17 ------------\n",
      "Train loss: 1.3145 | Train acc: 58.35%\n",
      "Validation loss: 1.4239 | Validation acc: 55.40%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 18 ------------\n",
      "Train loss: 1.3042 | Train acc: 58.72%\n",
      "Validation loss: 1.6639 | Validation acc: 50.06%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 19 ------------\n",
      "Train loss: 1.2802 | Train acc: 59.17%\n",
      "Validation loss: 1.6420 | Validation acc: 50.19%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 20 ------------\n",
      "Train loss: 1.2751 | Train acc: 59.96%\n",
      "Validation loss: 1.4634 | Validation acc: 55.06%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 21 ------------\n",
      "Train loss: 1.2434 | Train acc: 60.65%\n",
      "Validation loss: 1.6247 | Validation acc: 53.09%\n",
      "Time taken: 1min 37s\n",
      "Segmentation visualization saved at /kaggle/working/segmentation_epoch_20.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 22 ------------\n",
      "Train loss: 1.2105 | Train acc: 61.82%\n",
      "Validation loss: 1.5007 | Validation acc: 53.88%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 23 ------------\n",
      "Train loss: 1.1854 | Train acc: 62.93%\n",
      "Validation loss: 1.5258 | Validation acc: 54.60%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 24 ------------\n",
      "Train loss: 1.1516 | Train acc: 64.35%\n",
      "Validation loss: 1.5709 | Validation acc: 52.14%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 25 ------------\n",
      "Train loss: 1.1485 | Train acc: 64.43%\n",
      "Validation loss: 1.5587 | Validation acc: 53.80%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 26 ------------\n",
      "Train loss: 1.1118 | Train acc: 66.00%\n",
      "Validation loss: 1.6554 | Validation acc: 50.32%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 27 ------------\n",
      "Train loss: 1.0982 | Train acc: 66.67%\n",
      "Validation loss: 1.6111 | Validation acc: 50.27%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 28 ------------\n",
      "Train loss: 1.0688 | Train acc: 67.92%\n",
      "Validation loss: 1.5845 | Validation acc: 53.21%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:30<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 29 ------------\n",
      "Train loss: 1.0369 | Train acc: 68.76%\n",
      "Validation loss: 1.6235 | Validation acc: 49.17%\n",
      "Time taken: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:31<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ epoch 30 ------------\n",
      "Train loss: 1.0084 | Train acc: 69.97%\n",
      "Validation loss: 1.6175 | Validation acc: 52.33%\n",
      "Time taken: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "fcn8s_trained = train_model(fcn_8s,\n",
    "                            train_dataloader,\n",
    "                            val_dataloader,\n",
    "                            optimizer,\n",
    "                            loss_fn,\n",
    "                            num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4847b108",
   "metadata": {
    "papermill": {
     "duration": 0.068784,
     "end_time": "2024-11-26T18:30:48.056775",
     "exception": false,
     "start_time": "2024-11-26T18:30:47.987991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aea07162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:30:48.194153Z",
     "iopub.status.busy": "2024-11-26T18:30:48.193843Z",
     "iopub.status.idle": "2024-11-26T18:30:48.426658Z",
     "shell.execute_reply": "2024-11-26T18:30:48.425714Z"
    },
    "papermill": {
     "duration": 0.303506,
     "end_time": "2024-11-26T18:30:48.428726",
     "exception": false,
     "start_time": "2024-11-26T18:30:48.125220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open('/kaggle/working/loss_acc_dict.pkl', 'wb') as f:\n",
    "    pkl.dump(loss_acc_dict, f)\n",
    "\n",
    "torch.save(fcn8s_trained.state_dict(), '/kaggle/working/fcn8s.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 635428,
     "sourceId": 1132317,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1146.815304,
   "end_time": "2024-11-26T18:30:49.918156",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-26T18:11:43.102852",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
